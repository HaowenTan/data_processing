

# FastText 数据预训练与标注说明

本项目旨在基于 FastText 对大规模文本进行“是否包含数学内容”的分类。为了提高模型对数学语义的识别能力，我们设计了以下数据筛选与迭代增强流程。



### 数据来源

| 数据集           | 用途     | 说明                                                                |
| ------------- | ------ | ----------------------------------------------------------------- |
| `OpenWebMath` | 正样本    | 来自开源数学语料库，样本用于训练                |
| `FineWeb`     | 负样本初始集 | 原始语料库中随机采样，未经过筛选，可能包含部分数学内容                                       |

> **注：** 若无法联网访问 Hugging Face，可通过其镜像站点 [hf-mirror.com](https://hf-mirror.com) 下载 `.parquet` 格式数据文件，并使用 Python 的 `pandas` 包进行解析与加载。


### 文本预处理逻辑

使用 `clean_text()` 函数完成以下处理：

* 移除换行、多余空格、URL、Markdown符号、代码块标记等；
* 清理 Unicode 控制字符（如 `\u200e`、`\uFFFD`）；
* 标准化文本格式，避免特殊字符对训练造成干扰。



### 训练与迭代流程

我们采用多轮训练-筛选-增强的迭代策略提升模型判别力：

1. **初始训练**：

   * 使用 `OpenWebMath` 的样本作为正例；
   * 使用 `FineWeb` 随机采样的未标注数据作为负例。

2. **初筛并预测 FineWeb**：

   * 利用模型对 `FineWeb` 文本进行预测；

在包含 50,000 条正样本与 50,000 条负样本的训练集中，我们的模型在准确率和召回率上均达到了 0.9978。然而，在对测试集中的 10,000 条未标注 FineWeb 样本进行推理时，模型识别出其中 28 条为数学类内容。经人工逐条核查发现， 17 条虽未明确归属数学范畴，但涉及计算机、生物、化学、物理与经济等领域中的统计与计算分析，具备一定的数学相关性；其中的 5 条更明确包含数学建模、公式或方程等典型数学特征。其余12个样本则仅轻微涉及学术话题，与数学关联较弱。

该结果表明，尽管模型在训练集上表现优异，在实际应用中仍存在一定的**假阳性**问题（即实际为非数学类内容却被误判为数学类）。这一现象揭示了当前模型在处理跨学科文本及边界样本方面的泛化能力仍有待提升

#### 改进措施与评估

为了进一步提高对 FineWeb 数据集中数学类样本的识别精度，尤其是减少假阳性（即非数学类文本被误判为数学类）的出现，我们引入了 OpenWebMath 数据集中 `metadata` 字段中的 `found_math` 标签作为判别依据。具体地，将 `found_math=True` 的样本标记为正类（数学类），`found_math=False` 的样本标记为负类（非数学类），同时继续将 FineWeb 数据集视为负类来源，共同构建新的训练数据集。

本次训练样本的标签分布如下：

* 数学类样本（正类）：45,642 条
* 非数学类样本（负类）：54,357 条（FineWeb + OpenWebMath中高置信假阳性）

在新的训练集中，模型在准确率与召回率上均达到了 0.9975，与此前结果（0.9978）基本一致，表明尽管存在部分高置信假阳性样本，其在训练过程中并未对整体学习能力造成显著干扰，模型仍保持了优异的判别性能。

在对 FineWeb 中 10,000 条未标注样本进行推理时，模型共识别出 27 条数学类内容，其中与先前结果重合的样本有 15 条。对这批重合样本的预测概率大多集中在 0.6 至 0.85 区间，显示出模型在该类样本上的判断较为稳定。经人工复核，其中至少 11 条内容与数学密切相关，涵盖数学建模、物理计算、医学公式等；而个别高置信误判（如涉及摄像头操作或 I/O 系统的内容）反映出模型在处理部分“技术语境”时仍可能出现语义混淆，存在假阳性风险。

此外，模型此次新识别出的 13 条样本中，有 4 条涉及金融、社会保障统计与计算机实验笔记等具有弱数学特征的内容，另有 1 条为金融计算相关内容，在语义上与数学联系紧密，但其预测概率仅为 0.54，表明模型对此类样本仍然不够准确。


**迭代价值与未来优化路径**
从实验结果可见，尽管迭代训练能够修正个别高置信误判，但单轮误标修正仅涉及十余条样本，在训练集规模超过 10 万的前提下，对整体模型性能的影响极为有限。因此，进一步进行多轮迭代训练的边际收益有限。

与其持续小幅修正训练样本，不如从更系统的角度重新划分数据集，或引入多源异构数据与多标签弱监督策略，以提升模型在处理边界语义、多模态语境及跨领域文本中的泛化能力与稳健性。


### 模型推理结果分析（无标签数据）

为进一步验证模型在未见样本上的表现，我们选取了 FineWeb 数据集中未参与训练与测试的 5,000 条未标注样本，作为外部推理集。考虑到改进策略带来的增益有限，本轮推理仍采用原始模型进行。

推理结果显示，模型将其中 12 条样本判定为数学类，其余 4,988 条判定为非数学类。这一结果表明，模型在该数据集上整体预测较为保守，仅识别出少量可能具备数学相关性的内容，提示其在未标注数据中保持了一定的判断边界。

###  FastText 格式输出

输出文件示例 (`combined_fasttext.txt`) 格式如下：

```txt
__label__math     This paper introduces a new proof of the Riemann Hypothesis...
__label__non_math A detailed review of the best hiking backpacks in 2024...
```


###  评估指标

使用 FastText 自带的 `model.test()` 接口，获得如下评估指标：
* **测试样本总数**
* **准确率 (Precision)**
* **召回率 (Recall)**

* 通过 `sklearn.metrics.roc_auc_score()` 计算 AUC 指标

### 其他方案
FastText 是一种高效的文本分类工具，适用于小样本和简单任务，但它属于浅层模型，无法捕捉上下文语义，对多义词和长文本的处理能力较弱，难以胜任复杂的文本理解任务。

如果需要更强的语义建模能力，可以考虑替代方案如 TextCNN（结构简单、速度快）、BiLSTM（能建模序列依赖）、或基于预训练语言模型的 BERT 及其中文优化版本（如 NEZHA、ERNIE），这些方法在精度和表现上通常优于 FastText。
